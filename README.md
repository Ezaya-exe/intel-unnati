# NCERT Multilingual Doubt Solver ğŸ“š

> **Intel Unnati Grand Challenge 2024-25** | AI-powered educational assistant for NCERT curriculum

An intelligent doubt-solver for students in Grades 5-10 that uses NCERT textbooks as the sole knowledge source. Built with a Retrieval-Augmented Generation (RAG) pipeline, supporting Hindi and English with accurate citations.

![Python](https://img.shields.io/badge/Python-3.10-blue)
![Gradio](https://img.shields.io/badge/Gradio-4.0+-orange)
![LLM](https://img.shields.io/badge/LLM-Qwen3--4B-green)
![License](https://img.shields.io/badge/License-MIT-yellow)

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸŒ **Multilingual** | Hindi & English with auto language detection |
| ğŸ“Š **Grade Filtering** | Filter responses by Grade (5-10) and Subject |
| ğŸ“– **Citations** | Every answer includes source references |
| ğŸ’¬ **Conversation** | 5-turn conversation memory |
| ğŸ¤– **Smart Fallback** | "I don't know" for out-of-scope queries |
| ğŸ‘ **Feedback** | Rate answers with thumbs up/down |
| ğŸ“± **Mobile Ready** | Responsive UI for web and mobile |
| ğŸ” **Hybrid Search** | BM25 + Semantic search with reranking |

---

## ğŸš€ Quick Start

### Prerequisites
- **WSL2** with Ubuntu (Windows)
- **Conda** (Miniconda/Anaconda)
- **NVIDIA GPU** with CUDA 12.1+ (4GB+ VRAM)

### 1. Clone & Setup Environment

```bash
# Clone the repository
cd /mnt/d/study/python
git clone <repo-url> intel-unnati
cd intel-unnati

# Create conda environment
conda env create -f environment.yml
conda activate ncert_rag
```

### 2. Download NCERT Textbooks

```bash
python download_ncert.py
```
This downloads 465+ PDF chapters for Grades 5-10 (~2GB).

### 3. Download the LLM Model

```bash
# Download Qwen3-4B-Q4 GGUF model
mkdir -p models
cd models
wget https://huggingface.co/lmstudio-community/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q4_K_M.gguf
cd ..
```

### 4. Ingest PDFs into Vector Database

```bash
python ingest_pdfs.py
```
Creates vector embeddings for all textbook content.

### 5. Run the Application

```bash
# Web UI (Gradio)
python app.py
# Open http://localhost:7860

# REST API (FastAPI)
python api.py
# Open http://localhost:8000/docs
```

---

## ğŸ“ Project Structure

```
intel-unnati/
â”œâ”€â”€ app.py                  # ğŸŒ Gradio web interface
â”œâ”€â”€ api.py                  # ğŸ”Œ FastAPI REST endpoints
â”œâ”€â”€ evaluate.py             # ğŸ“Š Benchmarking script
â”œâ”€â”€ ingest_pdfs.py          # ğŸ“¥ PDF ingestion pipeline
â”œâ”€â”€ download_ncert.py       # â¬‡ï¸ NCERT textbook downloader
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ doubt_solver.py # ğŸ§  Main RAG orchestrator
â”‚   â”‚   â””â”€â”€ feedback.py     # ğŸ‘ Feedback collection
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ vector_store.py # ğŸ’¾ ChromaDB + advanced search
â”‚   â”‚   â”œâ”€â”€ hybrid_search.py# ğŸ” BM25 + semantic fusion
â”‚   â”‚   â”œâ”€â”€ reranker.py     # ğŸ“ˆ Cross-encoder reranking
â”‚   â”‚   â””â”€â”€ query_expansion.py # ğŸ”„ Query term expansion
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/
â”‚   â”‚   â”œâ”€â”€ qwen_gguf.py    # ğŸ¤– GGUF model inference
â”‚   â”‚   â””â”€â”€ llm_generator.py# ğŸ“ LLM wrapper
â”‚   â”‚
â”‚   â””â”€â”€ ocr/
â”‚       â””â”€â”€ extract_text.py # ğŸ“· Tesseract OCR
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_pdfs/           # ğŸ“š Downloaded NCERT PDFs
â”‚   â”œâ”€â”€ vector_db/          # ğŸ—„ï¸ ChromaDB storage
â”‚   â””â”€â”€ evaluation/         # ğŸ“‹ Benchmark datasets
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ DESIGN.md           # ğŸ“ Architecture documentation
â”‚
â”œâ”€â”€ environment.yml         # ğŸ“¦ Conda environment
â””â”€â”€ requirements.txt        # ğŸ“¦ Pip dependencies
```

---

## ğŸ¯ Performance Targets

| Metric | Target | Achieved |
|--------|--------|----------|
| End-to-end Latency | â‰¤ 3-5 seconds | âœ… ~2-4s |
| Citation Accuracy | â‰¥ 85% | Run `python evaluate.py` |
| GPU Memory | â‰¤ 4GB VRAM | âœ… ~3.5GB |

### Run Benchmarks

```bash
# Run full evaluation (50 questions)
python evaluate.py

# Run quick test (10 questions)
python evaluate.py -n 10
```

---

## ğŸ”Œ API Reference

### Chat Endpoint
```http
POST /api/chat
```

**Request:**
```json
{
  "question": "What is photosynthesis?",
  "grade": 10,
  "subject": "Science",
  "language": null
}
```

**Response:**
```json
{
  "question_id": "abc123",
  "answer": "Photosynthesis is the process by which...",
  "language": "English",
  "citations": [...],
  "latency_ms": 2340,
  "in_scope": true
}
```

### Feedback Endpoint
```http
POST /api/feedback
```

### Full API Docs
Open http://localhost:8000/docs after starting the API server.

---

## ğŸ“– Sample Questions

Try these questions to test the system:

| Grade | Subject | Question |
|-------|---------|----------|
| 10 | Science | What is the difference between evaporation and boiling? |
| 10 | Maths | Explain the Fundamental Theorem of Arithmetic |
| 9 | Social | What were the causes of the French Revolution? |
| 8 | Science | Describe the structure of an atom |
| 7 | Maths | What is the area of a circle? |
| 9 | Hindi | à¤ªà¥à¤°à¤•à¤¾à¤¶ à¤¸à¤‚à¤¶à¥à¤²à¥‡à¤·à¤£ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ? |

---

## ğŸ› ï¸ Technology Stack

- **LLM**: Qwen3-4B-GGUF (Q4_K_M quantized)
- **Embeddings**: paraphrase-multilingual-mpnet-base-v2
- **Vector DB**: ChromaDB
- **Keyword Search**: BM25 (rank-bm25)
- **Reranker**: ms-marco-MiniLM-L-6-v2
- **Web UI**: Gradio
- **API**: FastAPI
- **PDF Parser**: PyMuPDF

---

## ğŸ“Š Architecture

```
Query â†’ Language Detection â†’ Query Expansion â†’ Hybrid Search (BM25+Semantic)
                                                        â†“
                                               Cross-Encoder Rerank
                                                        â†“
Answer â† Citation Formatter â† LLM Generation â† Context Builder
```

For detailed architecture, see [docs/DESIGN.md](docs/DESIGN.md).

---

## ğŸ”§ Configuration

Create a `.env` file:

```env
# Model Configuration
GGUF_MODEL_PATH=models/Qwen3-4B-Q4_K_M.gguf
N_GPU_LAYERS=35
N_CTX=4096

# Vector Store
VECTOR_DB_PATH=data/vector_db
EMBEDDING_MODEL=paraphrase-multilingual-mpnet-base-v2

# Search Settings
HYBRID_SEARCH=true
RERANKING=true
QUERY_EXPANSION=true
```

---

## ğŸ“œ License

MIT License - See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- **Intel Unnati Program** for the problem statement
- **NCERT** for providing open-access textbooks
- **Qwen Team** for the multilingual LLM

---

*Built with â¤ï¸ for students across India*
